{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e8bc25",
   "metadata": {},
   "source": [
    "# Product Recommendation Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1566007",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "We load the dataset and define the target variable as 'is_recommended', indicating whether a user would recommend a product. To ensure balanced training, we sampled equal numbers of positive and negative examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b10a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\")))\n",
    "import pandas as pd\n",
    "\n",
    "# loading the preprocessed data \n",
    "from src.data_preprocessing import load_processedDfs\n",
    "from src.sentiment import sentiment_vader\n",
    "\n",
    "df = load_processedDfs()\n",
    "\n",
    "# loading the cleaned data\n",
    "results = [sentiment_vader(text) for text in df['review_text']]\n",
    "df[['vader_score', 'vader_label']] = pd.DataFrame(results, index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de781c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_recommended\n",
       "1.0    778160\n",
       "0.0    148263\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_recommended'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df2c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_recommended\n",
       "1.0    148000\n",
       "0.0    148000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# balancing the dataset\n",
    "balanced_df = pd.concat([\n",
    "    df[df['is_recommended']==1].sample(148000,random_state=42),\n",
    "    df[df['is_recommended']==0].sample(148000,random_state=42)\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "balanced_df['is_recommended'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ecf119",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Relevant features were extracted including product attributed, reviews and skin type. All the categorical column was transformed into numerical using ColumnTransformer method. Also we used textblob library to get the numerical value fo the review text column.\n",
    "\n",
    "An XGBoost classifer was trained on this feature set. This tree-based model captures nonlinear relationship and feature interactions, making it well suited for product recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c788e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# feature extraction\n",
    "balanced_df['sentiment'] = balanced_df['clean_text'].apply(\n",
    "    lambda x: TextBlob(x).sentiment.polarity\n",
    ")\n",
    "\n",
    "numeric_features = [\n",
    "    'loves_count','product_rating','price_usd','reviews',\n",
    "    'sephora_exclusive','total_feedback_count','new',\n",
    "    'sentiment', 'sentiment_score'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'skin_type','sentiment_label'\n",
    "]\n",
    "\n",
    "# transforming categorical columns to numerical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# splitting the data into train and test set\n",
    "X = balanced_df[numeric_features + categorical_features]\n",
    "y = balanced_df['is_recommended']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# setting up model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.75      0.75     29600\n",
      "         1.0       0.75      0.76      0.76     29600\n",
      "\n",
      "    accuracy                           0.76     59200\n",
      "   macro avg       0.76      0.76      0.76     59200\n",
      "weighted avg       0.76      0.76      0.76     59200\n",
      "\n",
      "Accuracy Score: 0.7562331081081081\n",
      "[[22138  7462]\n",
      " [ 6969 22631]]\n"
     ]
    }
   ],
   "source": [
    "# model prediction\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1102b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8352349194211104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_prob = model.predict_proba(X_test)[:,1]\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce8f85",
   "metadata": {},
   "source": [
    "Analysis: The model achieves 75% accuracy and an AUC of 0.83 on the test set, indicating a strong ability to distinguish between recommended and non-recommended products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea01584",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "The importance of each feature was analyzed to understand which factors most influence product recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bb286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num__sentiment_score</td>\n",
       "      <td>0.199496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cat__sentiment_label_negative</td>\n",
       "      <td>0.194930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cat__sentiment_label_positive</td>\n",
       "      <td>0.189548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>num__total_feedback_count</td>\n",
       "      <td>0.156129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num__product_rating</td>\n",
       "      <td>0.078296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>num__sentiment</td>\n",
       "      <td>0.047144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cat__sentiment_label_neutral</td>\n",
       "      <td>0.019347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>num__reviews</td>\n",
       "      <td>0.017567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num__price_usd</td>\n",
       "      <td>0.017234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num__loves_count</td>\n",
       "      <td>0.017221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num__sephora_exclusive</td>\n",
       "      <td>0.017062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>num__new</td>\n",
       "      <td>0.012310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cat__skin_type_normal</td>\n",
       "      <td>0.009574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cat__skin_type_oily</td>\n",
       "      <td>0.009011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cat__skin_type_dry</td>\n",
       "      <td>0.008305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cat__skin_type_combination</td>\n",
       "      <td>0.006827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  importance\n",
       "8            num__sentiment_score    0.199496\n",
       "13  cat__sentiment_label_negative    0.194930\n",
       "15  cat__sentiment_label_positive    0.189548\n",
       "5       num__total_feedback_count    0.156129\n",
       "1             num__product_rating    0.078296\n",
       "7                  num__sentiment    0.047144\n",
       "14   cat__sentiment_label_neutral    0.019347\n",
       "3                    num__reviews    0.017567\n",
       "2                  num__price_usd    0.017234\n",
       "0                num__loves_count    0.017221\n",
       "4          num__sephora_exclusive    0.017062\n",
       "6                        num__new    0.012310\n",
       "11          cat__skin_type_normal    0.009574\n",
       "12            cat__skin_type_oily    0.009011\n",
       "10             cat__skin_type_dry    0.008305\n",
       "9      cat__skin_type_combination    0.006827"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = model.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "xgb_model = model.named_steps['classifier']\n",
    "\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "feature_importance_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c1e5a",
   "metadata": {},
   "source": [
    "Analysis: Sentiment score and label plays a key role in driving recommendation system suggesting user words holds great value in making a product successful or not"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
